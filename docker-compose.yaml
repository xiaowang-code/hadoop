# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

x-hadoop-common: &hadoop-common
  image: apache/hadoop:3.4.1
  env_file:
    - ./config
  networks:
    - hadoop-net
  ulimits:
    nofile:
      soft: 65536
      hard: 65536
    nproc:
      soft: 65536
      hard: 65536

services:
  namenode:
    <<: *hadoop-common
    container_name: hadoop-namenode
    hostname: namenode
    command: ["hdfs", "namenode"]
    ports:
      - 9870:9870
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
    volumes:
      - hadoop-namenode:/hadoop/dfs/name
  
  datanode:
    <<: *hadoop-common
    container_name: hadoop-datanode
    command: ["hdfs", "datanode"]
    volumes:
      - hadoop-datanode:/hadoop/dfs/data
    depends_on:
      - namenode
  
  resourcemanager:
    <<: *hadoop-common
    container_name: hadoop-resourcemanager
    hostname: resourcemanager
    command: ["yarn", "resourcemanager"]
    ports:
      - 8088:8088
    depends_on:
      - namenode
      - datanode
    
  nodemanager:
    <<: *hadoop-common
    container_name: hadoop-nodemanager
    command: ["yarn", "nodemanager"]
    depends_on:
      - resourcemanager

  historyserver:
    <<: *hadoop-common
    container_name: hadoop-historyserver
    command: ["mapred", "historyserver"]
    ports:
      - 19888:19888
    depends_on:
      - namenode
      - datanode

  mysql:
    image: mysql:8.0
    container_name: hive-mysql
    hostname: mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: metastore
      MYSQL_USER: hive
      MYSQL_PASSWORD: hive
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql
      - ./hive/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - hadoop-net
  
  hive-metastore:
    image: apache/hive:4.1.0
    container_name: hive-metastore
    hostname: hive-metastore
    depends_on:
      - mysql
      - namenode
      - datanode
    ports:
      - "9083:9083"
    environment:
      SERVICE_NAME: metastore
      DB_DRIVER: mysql
      SERVICE_OPTS: >-
        -Dfs.defaultFS=hdfs://namenode:8020
        -Dhive.metastore.warehouse.dir=hdfs://namenode:8020/user/hive/warehouse
        -Dhive.users.in.admin.role=hive,admin
        -Djavax.jdo.option.ConnectionDriverName=com.mysql.cj.jdbc.Driver
        -Djavax.jdo.option.ConnectionURL=jdbc:mysql://mysql:3306/metastore?createDatabaseIfNotExist=true&useSSL=false&allowPublicKeyRetrieval=true
        -Djavax.jdo.option.ConnectionUserName=hive
        -Djavax.jdo.option.ConnectionPassword=hive
    volumes:
      - ./jdbc-drivers/mysql-connector-j-8.0.33.jar:/opt/hive/lib/mysql-connector-java-8.0.33.jar:ro
    networks:
      - hadoop-net

  hive-server:
    container_name: hive-server
    image: apache/hive:4.1.0
    hostname: hive-server
    depends_on:
      - hive-metastore
    ports:
      - "10000:10000"
      - "10002:10002"
    environment:
      SERVICE_NAME: hiveserver2
      IS_RESUME: false
      SERVICE_OPTS: >-
        -Dfs.defaultFS=hdfs://namenode:8020
        -Dhive.metastore.uris=thrift://hive-metastore:9083
        -Dhive.metastore.warehouse.dir=hdfs://namenode:8020/user/hive/warehouse
        -Dhive.security.authorization.enabled=true
        -Dhive.server2.enable.doAs=true
        -Dhive.users.in.admin.role=hive,admin
    networks:
      - hadoop-net

  spark:
    image: apache/spark:3.5.6
    container_name: spark
    hostname: spark
    depends_on:
      - hive-server
      - hive-metastore
    environment:
      SPARK_MASTER: local
      HIVE_METASTORE_URI: thrift://hive-metastore:9083
    ports:
      - "4040:4040"
    networks:
      - hadoop-net
    entrypoint: [ "/bin/bash", "-c", "while true; do sleep 1000; done" ]


volumes:
  hadoop-namenode:
  hadoop-datanode:
  mysql_data:

networks:
  hadoop-net:
    driver: bridge